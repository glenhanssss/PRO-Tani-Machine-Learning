{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpp_DUFs6Odq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef14e45c-fb4c-4dfd-d402-7c6615b6dc98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 5663 images belonging to 5 classes.\n",
            "Found 1414 images belonging to 5 classes.\n",
            "Epoch 1/10\n",
            "177/177 [==============================] - 187s 1s/step - loss: 1.1944 - accuracy: 0.5230 - val_loss: 0.8702 - val_accuracy: 0.6761\n",
            "Epoch 2/10\n",
            "177/177 [==============================] - 179s 1s/step - loss: 0.7581 - accuracy: 0.7275 - val_loss: 0.6582 - val_accuracy: 0.7638\n",
            "Epoch 3/10\n",
            "177/177 [==============================] - 185s 1s/step - loss: 0.5804 - accuracy: 0.7976 - val_loss: 0.4473 - val_accuracy: 0.8373\n",
            "Epoch 4/10\n",
            "177/177 [==============================] - 184s 1s/step - loss: 0.4273 - accuracy: 0.8495 - val_loss: 0.3245 - val_accuracy: 0.8798\n",
            "Epoch 5/10\n",
            "177/177 [==============================] - 176s 994ms/step - loss: 0.3196 - accuracy: 0.8872 - val_loss: 0.2559 - val_accuracy: 0.8861\n",
            "Epoch 6/10\n",
            "177/177 [==============================] - 182s 1s/step - loss: 0.2672 - accuracy: 0.9043 - val_loss: 0.1829 - val_accuracy: 0.9392\n",
            "Epoch 7/10\n",
            "177/177 [==============================] - 175s 987ms/step - loss: 0.2308 - accuracy: 0.9204 - val_loss: 0.1343 - val_accuracy: 0.9547\n",
            "Epoch 8/10\n",
            "177/177 [==============================] - 182s 1s/step - loss: 0.1936 - accuracy: 0.9325 - val_loss: 0.1328 - val_accuracy: 0.9512\n",
            "Epoch 9/10\n",
            "177/177 [==============================] - 183s 1s/step - loss: 0.1632 - accuracy: 0.9423 - val_loss: 0.1492 - val_accuracy: 0.9420\n",
            "Epoch 10/10\n",
            "177/177 [==============================] - 182s 1s/step - loss: 0.1522 - accuracy: 0.9437 - val_loss: 0.2137 - val_accuracy: 0.9201\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the path to the main folder containing subfolders for each class in your Google Drive\n",
        "data_directory = '/content/drive/MyDrive/CNN_PROTANI'\n",
        "\n",
        "# Set the image dimensions and batch size\n",
        "image_width, image_height = 128, 128\n",
        "batch_size = 32\n",
        "\n",
        "# Create separate ImageDataGenerator objects for training and validation data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,  # Normalize pixel values to [0, 1]\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2  # Splitting 20% of the data as validation set\n",
        ")\n",
        "\n",
        "# Generate training data from the images in the subfolders\n",
        "train_data_generator = train_datagen.flow_from_directory(\n",
        "    directory=data_directory,\n",
        "    target_size=(image_width, image_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    subset='training'  # Subset of the data for training\n",
        ")\n",
        "\n",
        "# Generate validation data from the images in the subfolders\n",
        "validation_data_generator = train_datagen.flow_from_directory(\n",
        "    directory=data_directory,\n",
        "    target_size=(image_width, image_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    subset='validation'  # Subset of the data for validation\n",
        ")\n",
        "\n",
        "# Get the number of classes\n",
        "num_classes = len(train_data_generator.class_indices)\n",
        "\n",
        "# Define the CNN model with dropout layers\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_width, image_height, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),  # Dropout layer with dropout rate of 0.25\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),  # Dropout layer with dropout rate of 0.25\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),  # Dropout layer with dropout rate of 0.25\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),  # Dropout layer with dropout rate of 0.5\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model with validation\n",
        "model.fit(\n",
        "    train_data_generator,\n",
        "    epochs=10,\n",
        "    validation_data=validation_data_generator\n",
        ")\n",
        "\n",
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/CNN_PROTANI/trained_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/CNN_PROTANI/trained_model_1.h5')"
      ],
      "metadata": {
        "id": "aze2xl9oCwEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open (\"model_cnn_new.tflite\", 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl6JXH5VLb90",
        "outputId": "35bc8594-00be-4f55-8e00-21da8b763f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/CNN_PROTANI/trained_model_1.h5')\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTONl4XyRJlpfXPCJW_B4w__6ADgTF49TZ_Nz3hrj6AeO7dZ-iohf51vNvs-8cggAZ8AIs&usqp=CAU'  # Replace with the URL of your image\n",
        "with urllib.request.urlopen(url) as response:\n",
        "    img_array = np.asarray(bytearray(response.read()), dtype=np.uint8)\n",
        "    img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
        "\n",
        "img = cv2.resize(img, (128, 128))\n",
        "img = np.reshape(img, [1, 128, 128, 3])\n",
        "\n",
        "classes = model.predict(img)\n",
        "\n",
        "print(classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fbp9UaVvv_1a",
        "outputId": "515d64c9-3f9b-415b-dd0d-7d0eb7e0c28a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 95ms/step\n",
            "[[0.0000000e+00 1.4123285e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00]]\n"
          ]
        }
      ]
    }
  ]
}